{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas\n",
    "! pip install pydicom\n",
    "! pip install seaborn\n",
    "\n",
    "import glob, pylab, pandas as pd\n",
    "import pydicom, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.dark_palette(\"purple\"))\n",
    "\n",
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import reduce\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, Dropout2d, MaxPool2d, BatchNorm1d, BatchNorm2d, ReLU, ELU\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax, dropout, dropout2d\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show files in data\n",
    "!ls data\n",
    "\n",
    "# display label format\n",
    "df = pd.read_csv('data/stage_1_train_labels.csv')\n",
    "\n",
    "\n",
    "# \n",
    "batch_size = 16\n",
    "No_train_samples = 1024\n",
    "No_test_samples = 128\n",
    "No = 4\n",
    "patientId = df['patientId'][No]\n",
    "dcm_file = 'data/stage_1_train_images/%s.dcm' % patientId\n",
    "dcm_data = pydicom.read_file(dcm_file)\n",
    "#print(df.iloc[No])\n",
    "\n",
    "\n",
    "#print(np.unique(df.Target))\n",
    "#print(df['patientId'])\n",
    "\n",
    "IMG_SIZE = 224\n",
    "img_dimension = [IMG_SIZE,IMG_SIZE] # New size of xray images. \n",
    "unq, idx = np.unique(df['patientId'], return_index = True) # Get only unique entrances from the provided data (some patients occur multiple times)\n",
    "\n",
    "# Reshape images and match to corresponding label in new dataframe\n",
    "Target = []\n",
    "Image = []\n",
    "for i in range(0,No_train_samples):\n",
    "    Target.append(df.Target[idx[i]]) # Get label  \n",
    "    patientId = df['patientId'][idx[i]] # Get patient id from the idx \n",
    "    dcm_file = 'data/stage_1_train_images/%s.dcm' % patientId # find the image-file corresponding to the patient id\n",
    "    dcm_data = pydicom.read_file(dcm_file) # Load the image \n",
    "    Image.append(resize(dcm_data.pixel_array, output_shape=img_dimension, mode='reflect', anti_aliasing=True)) # resize image\n",
    "    if not i % 100:\n",
    "        print(i)\n",
    "print(i)\n",
    "\n",
    "# Convert to Tensor\n",
    "Target = torch.Tensor(Target)\n",
    "Image = torch.Tensor(Image)\n",
    "Image = Image.unsqueeze(1)\n",
    "\n",
    "# Construct DataLoader\n",
    "loader = TensorDataset(Image, Target)\n",
    "train_loader = DataLoader(loader, batch_size=batch_size, shuffle = True)\n",
    "print('Train data loaded')\n",
    "        \n",
    "Target = []\n",
    "Image = []\n",
    "for i in range(0,No_test_samples):\n",
    "    Target.append(df.Target[idx[No_train_samples+i]]) # Get label  \n",
    "    patientId = df['patientId'][idx[No_train_samples+i]] # Get patient id from the idx \n",
    "    dcm_file = 'data/stage_1_train_images/%s.dcm' % patientId # find the image-file corresponding to the patient id\n",
    "    dcm_data = pydicom.read_file(dcm_file) # Load the image \n",
    "    Image.append(resize(dcm_data.pixel_array, output_shape=img_dimension, mode='reflect', anti_aliasing=True)) # resize image\n",
    "    if not i % 100:\n",
    "        print(i)\n",
    "print(i)\n",
    "\n",
    "# Convert to Tensor\n",
    "Target = torch.Tensor(Target)\n",
    "Image = torch.Tensor(Image)\n",
    "Image = Image.unsqueeze(1)\n",
    "print(Image.shape)\n",
    "\n",
    "# Construct DataLoader\n",
    "loader = TensorDataset(Image, Target)\n",
    "test_loader = DataLoader(loader, batch_size=batch_size, shuffle = True)\n",
    "print('Test data loaded')\n",
    "\n",
    "# Show an example image\n",
    "im = Image[0]\n",
    "im = im.squeeze(0)\n",
    "pylab.imshow(im, cmap=pylab.cm.gist_gray)\n",
    "pylab.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define size variables\n",
    "height = IMG_SIZE\n",
    "width = IMG_SIZE\n",
    "channels = 1\n",
    "num_features = 224**2\n",
    "\n",
    "# Regulization\n",
    "L2_reg = 1e-6\n",
    "\n",
    "# 1. Conv Layer\n",
    "conv_out_channels_1 = 4\n",
    "conv_kernel_1 = 5\n",
    "conv_padding_1 = 2\n",
    "conv_stride_1 = 1\n",
    "\n",
    "# 1. MaxPool Layer\n",
    "pool_kernel_1 = conv_kernel_1\n",
    "pool_padding_1 = 2\n",
    "pool_stride_1 = 2\n",
    "\n",
    "# 2. Conv Layer\n",
    "conv_out_channels_2 = 8\n",
    "conv_kernel_2 = 5\n",
    "conv_padding_2 = conv_padding_1\n",
    "conv_stride_2 = 1\n",
    "\n",
    "# 2. MaxPool Layer\n",
    "pool_kernel_2 = 3\n",
    "pool_padding_2 = 0\n",
    "pool_stride_2 = 2\n",
    "\n",
    "\n",
    "# Calculating the dimensions \n",
    "def compute_conv_dim(height, width, kernel_size, padding_size, stride_size):\n",
    "    height_new = int((height - kernel_size + 2 * padding_size) / stride_size + 1)\n",
    "    width_new =  int((width  - kernel_size + 2 * padding_size) / stride_size + 1)\n",
    "    return [height_new, width_new]\n",
    "\n",
    "def compute_final_dimension(height, width, last_num_channels):\n",
    "    # First conv layer\n",
    "    CNN_height, CNN_width = compute_conv_dim(height, width, \n",
    "                                             conv_kernel_1, conv_padding_1, conv_stride_1)\n",
    "    # First maxpool layer\n",
    "    CNN_height, CNN_width = compute_conv_dim(CNN_height, CNN_width, \n",
    "                                             pool_kernel_1, pool_padding_1, pool_stride_1)\n",
    "    # Second conv layer\n",
    "    CNN_height, CNN_width = compute_conv_dim(CNN_height, CNN_width,\n",
    "                                             conv_kernel_2, conv_padding_2, conv_stride_2)\n",
    "    # Second maxpool layer\n",
    "    CNN_height, CNN_width = compute_conv_dim(CNN_height, CNN_width,\n",
    "                                             pool_kernel_2, pool_padding_2, pool_stride_2)\n",
    "    final_dim = CNN_height * CNN_width * last_num_channels\n",
    "    return final_dim\n",
    "\n",
    "\n",
    "######## Image has to be: (num, channels, height, width)!!!! #########\n",
    "class CNN_VAE(nn.Module):\n",
    "    def __init__(self, latent_features, num_samples):\n",
    "        super(CNN_VAE, self).__init__()\n",
    "        \n",
    "        self.latent_features = latent_features\n",
    "        self.num_samples = num_samples\n",
    "        \n",
    "        # Calculate final size of the CNN\n",
    "        self.final_dim = compute_final_dimension(height,width,conv_out_channels_2)\n",
    "\n",
    "        ## CNN encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            Conv2d(in_channels=channels,\n",
    "                             out_channels=conv_out_channels_1,\n",
    "                             kernel_size=conv_kernel_1,\n",
    "                             stride=conv_stride_1,\n",
    "                             padding=conv_padding_1),\n",
    "            \n",
    "            MaxPool2d(kernel_size=pool_kernel_1, \n",
    "                             stride=pool_stride_1,\n",
    "                             padding=pool_padding_1),\n",
    "            ReLU(),\n",
    "            BatchNorm2d(conv_out_channels_1),\n",
    "            Dropout2d(p=0.2),\n",
    "            \n",
    "            Conv2d(in_channels=conv_out_channels_1,\n",
    "                             out_channels=conv_out_channels_2,\n",
    "                             kernel_size=conv_kernel_2,\n",
    "                             stride=conv_stride_2,\n",
    "                             padding=conv_padding_2),\n",
    "            \n",
    "            MaxPool2d(kernel_size=pool_kernel_2,\n",
    "                             stride=pool_stride_2,\n",
    "                             padding=pool_padding_2),\n",
    "            ReLU(),\n",
    "            BatchNorm2d(conv_out_channels_2),\n",
    "            Dropout2d(p=0.2)\n",
    "        )\n",
    "        \n",
    "        self.CNN_to_latent = Linear(in_features=self.final_dim, out_features=self.latent_features*2)\n",
    "        \n",
    "        # The latent code must be decoded into the original image\n",
    "        self.decoder = nn.Sequential(\n",
    "            Linear(in_features=self.latent_features, out_features=128),\n",
    "            #BatchNorm1d(num_features=128, eps=1e-3),\n",
    "            ELU(),\n",
    "            Linear(in_features=128, out_features=256),\n",
    "            #BatchNorm1d(num_features=256),\n",
    "            ELU(),\n",
    "            nn.Linear(in_features=256, out_features=num_features*2) # Double because of a man reconstruction and \n",
    "        )                                                           # variance reconstruction\n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        outputs = {}\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view( batch_size, -1)\n",
    "        # x = x.view(num_samples,-1) # fold out the CNN layers\n",
    "        x = self.CNN_to_latent(x)\n",
    "        \n",
    "        # Split encoder outputs into a mean and variance vector\n",
    "        mu, log_var = torch.chunk(x, 2, dim=-1)\n",
    "        \n",
    "        # Make sure that the log variance is positive\n",
    "        log_var = softplus(log_var)\n",
    "        \n",
    "        # :- Reparametrisation trick\n",
    "        # a sample from N(mu, sigma) is mu + sigma * epsilon\n",
    "        # where epsilon ~ N(0, 1)\n",
    "                \n",
    "        # Don't propagate gradients through randomness\n",
    "        with torch.no_grad():\n",
    "            batch_size = mu.size(0)\n",
    "            epsilon = torch.randn(batch_size, self.num_samples, self.latent_features)\n",
    "            \n",
    "            if cuda:\n",
    "                epsilon = epsilon.cuda()\n",
    "        \n",
    "        sigma = torch.exp(log_var/2)\n",
    "        \n",
    "        # We will need to unsqueeze to turn\n",
    "        # (batch_size, latent_dim) -> (batch_size, 1, latent_dim)\n",
    "        z = mu.unsqueeze(1) + epsilon * sigma.unsqueeze(1)        \n",
    "        \n",
    "        # Run through decoder\n",
    "        x = self.decoder(z)\n",
    "        x_mean, x_log_var = torch.chunk(x,2,dim=-1) # the mean and log_var reconstructions from the decoder\n",
    "        \n",
    "        # The original digits are on the scale [0, 1]\n",
    "        x_hat = torch.sigmoid(x_mean) # to scale for showing an image\n",
    "        \n",
    "        # Mean over samples\n",
    "        x_hat = torch.mean(x_hat, dim=1)\n",
    "        \n",
    "        # Resize x_hat from [batch_size, no_features] to [batch_size, channels, height, width]\n",
    "        x_hat = x_hat.view( batch_size, 1, height, width)\n",
    "        \n",
    "        outputs[\"x_hat\"] = x_hat # This is used for visulizations only \n",
    "        outputs[\"z\"] = z\n",
    "        outputs[\"mu\"] = mu\n",
    "        outputs[\"log_var\"] = log_var\n",
    "        \n",
    "        # image recontructions (notice they are outputted as matrices)\n",
    "        outputs[\"x_mean\"] = torch.reshape(x_mean,(-1,height,width)) # mean reconstructions (for loss!!!)\n",
    "        outputs[\"x_log_var\"] = torch.reshape(x_log_var,(-1,height,width)) # log var reconstructions (for loss!!!)\n",
    "        \n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "latent_features = 4\n",
    "# The number of samples used then initialising the VAE, \n",
    "# is number of samples drawn from the distribution\n",
    "num_samples = 10\n",
    "\n",
    "net = CNN_VAE(latent_features, num_samples)\n",
    "\n",
    "# Transfer model to GPU if available\n",
    "if cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import binary_cross_entropy\n",
    "from torch import optim\n",
    "import math\n",
    "\n",
    "def Gaussian_density(sample_img,mu_img,log_var_img):\n",
    "    c = - 0.5 * math.log(2 * math.pi)\n",
    "    density = c - log_var_img/2 - (sample_img - mu_img)**2/(2 * torch.exp(log_var_img))\n",
    "    return torch.sum(density,dim = 1) # \n",
    "\n",
    "def ELBO_loss(sample_img, mu_img, log_var_img, mu, log_var):\n",
    "    \n",
    "    # Reconstruction error, log[p(x|z)]\n",
    "    # Sum over features\n",
    "        # Old code\n",
    "        #likelihood = -binary_cross_entropy(y, t, reduction=\"none\")\n",
    "        #likelihood = likelihood.view(likelihood.size(0), -1).sum(1)\n",
    "\n",
    "    # New code with guassian density\n",
    "    likelihood = Gaussian_density(sample_img, mu_img, log_var_img)\n",
    "    \n",
    "    # Regularization error: \n",
    "    # Kulback-Leibler divergence between approximate posterior, q(z|x)\n",
    "    # and prior p(z) = N(z | mu, sigma*I).\n",
    "    \n",
    "    # In the case of the KL-divergence between diagonal covariance Gaussian and \n",
    "    # a standard Gaussian, an analytic solution exists. Using this excerts a lower\n",
    "    # variance estimator of KL(q||p)\n",
    "    kl = -0.5 * torch.sum(1 + log_var - mu**2 - torch.exp(log_var), dim=1)\n",
    "\n",
    "    # Combining the two terms in the evidence lower bound objective (ELBO) \n",
    "    # mean over batch\n",
    "    ELBO = torch.mean(likelihood) - torch.mean(kl)\n",
    "    \n",
    "    # notice minus sign as we want to maximise ELBO\n",
    "    return -ELBO, kl.sum()\n",
    "\n",
    "\n",
    "# define our optimizer\n",
    "# The Adam optimizer works really well with VAEs.\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = ELBO_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "x, _ = next(iter(train_loader))\n",
    "x = Variable(x)\n",
    "if cuda:\n",
    "    x = x.cuda()\n",
    "\n",
    "outputs = net(x)\n",
    "\n",
    "x_hat = outputs[\"x_hat\"]\n",
    "mu, log_var = outputs[\"mu\"], outputs[\"log_var\"]\n",
    "mu_img, log_var_img = outputs[\"x_mean\"], outputs[\"x_log_var\"]\n",
    "z = outputs[\"z\"]\n",
    "\n",
    "print(torch.sum(torch.isnan(x)))\n",
    "print(torch.sum(torch.isnan(x_hat)))\n",
    "print(outputs[\"mu\"])\n",
    "print(outputs[\"log_var\"])\n",
    "print(net.CNN_to_latent.weight)\n",
    "\n",
    "loss, kl = loss_function(x, mu_img, log_var_img, mu, log_var)\n",
    "\n",
    "print(x.shape)\n",
    "print(x_hat.shape)\n",
    "print(z.shape)\n",
    "print(loss)\n",
    "print(kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Deleting variable Image and reload package Image\n",
    "%reset_selective -f \"^Image$\"\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "num_epochs = No_train_samples // batch_size\n",
    "tmp_img = \"tmp_vae_out.png\"\n",
    "show_sampling_points = False\n",
    "classes = [0,1]\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "train_kl, valid_kl = [], []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch_loss, batch_kl = [], []\n",
    "    net.train()\n",
    "    \n",
    "    # Go through each batch in the training dataset using the loader\n",
    "    # Note that y is not necessarily known as it is here\n",
    "    for x, y in train_loader:\n",
    "        x = Variable(x)\n",
    "        # This is an alternative way of putting\n",
    "        # a tensor on the GPU\n",
    "        x = x.to(device)\n",
    "        \n",
    "        outputs = net(x)\n",
    "        x_hat = outputs['x_hat']\n",
    "        mu, log_var = outputs['mu'], outputs['log_var']\n",
    "        mu_img, log_var_img = outputs[\"x_mean\"], outputs[\"x_log_var\"]\n",
    "\n",
    "        # elbo, kl = loss_function(x_hat, x, mu, log_var)\n",
    "        elbo, kl = loss_function(x, mu_img, log_var_img, mu, log_var)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        elbo.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss.append(elbo.item())\n",
    "        batch_kl.append(kl.item())\n",
    "\n",
    "    train_loss.append(np.mean(batch_loss))\n",
    "    train_kl.append(np.mean(batch_kl))\n",
    "\n",
    "    # Evaluate, do not propagate gradients\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        \n",
    "        # Just load a single batch from the test loader\n",
    "        x, y = next(iter(test_loader))\n",
    "        x = Variable(x)\n",
    "        \n",
    "        x = x.to(device)\n",
    "        \n",
    "        outputs = net(x)\n",
    "        x_hat = outputs['x_hat']\n",
    "        mu, log_var = outputs['mu'], outputs['log_var']\n",
    "        mu_img, log_var_img = outputs[\"x_mean\"], outputs[\"x_log_var\"]\n",
    "        z = outputs[\"z\"]\n",
    "    \n",
    "        # elbo, kl = loss_function(x_hat, x, mu, log_var)\n",
    "        elbo, kl = loss_function(x, mu_img, log_var_img, mu, log_var)\n",
    "        \n",
    "        # We save the latent variable and reconstruction for later use\n",
    "        # we will need them on the CPU to plot\n",
    "        x = x.to(\"cpu\")\n",
    "        x_hat = x_hat.to(\"cpu\")\n",
    "        z = z.detach().to(\"cpu\").numpy()\n",
    "        \n",
    "        valid_loss.append(elbo.item())\n",
    "        valid_kl.append(kl.item())\n",
    "    \n",
    "    if epoch == 0:\n",
    "        continue\n",
    "    \n",
    "    # -- Plotting --\n",
    "    f, axarr = plt.subplots(3, 2, figsize=(20, 20))\n",
    "\n",
    "    # Loss\n",
    "    ax = axarr[0, 0]\n",
    "    ax.set_title(\"ELBO\")\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Error')\n",
    "\n",
    "    ax.plot(np.arange(epoch+1), train_loss, color=\"black\")\n",
    "    ax.plot(np.arange(epoch+1), valid_loss, color=\"gray\", linestyle=\"--\")\n",
    "    ax.legend(['Training', 'Validation'])\n",
    "\n",
    "    # Latent space\n",
    "    ax = axarr[0, 1]\n",
    "\n",
    "    ax.set_title('Latent space')\n",
    "    ax.set_xlabel('Dimension 1')\n",
    "    ax.set_ylabel('Dimension 2')\n",
    "    \n",
    "    rows = 4\n",
    "    columns = batch_size // rows\n",
    "    \n",
    "    span = np.linspace(-4, 4, rows)\n",
    "    grid = np.dstack(np.meshgrid(span, span)).reshape(-1, 2)\n",
    "    \n",
    "    # If you want to use a dimensionality reduction method you can use\n",
    "    # for example PCA by projecting on two principal dimensions\n",
    "\n",
    "    z = PCA(n_components=2).fit_transform(z.reshape(-1,latent_features))\n",
    "    z = z.reshape(batch_size,num_samples,2)\n",
    "#     print(z.shape)\n",
    "#     print(z.reshape(-1,latent_features).shape)\n",
    "    colors = iter(plt.get_cmap('Set1')(np.linspace(0, 1.0, len(classes))))\n",
    "    for c in classes:\n",
    "        ax.scatter(*z[c == y.numpy()].reshape(-1, 2).T, c=next(colors), marker='o', label=c)\n",
    "        \n",
    "    if show_sampling_points:\n",
    "        ax.scatter(*grid.T, color=\"k\", marker=\"x\", alpha=0.5, label=\"Sampling points\")\n",
    "\n",
    "    ax.legend()\n",
    "    \n",
    "    # KL / reconstruction\n",
    "    ax = axarr[1, 0]\n",
    "    \n",
    "    ax.set_title(\"Kullback-Leibler Divergence\")\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('KL divergence')\n",
    "\n",
    "\n",
    "    ax.plot(np.arange(epoch+1), train_kl, color=\"black\")\n",
    "    ax.plot(np.arange(epoch+1), valid_kl, color=\"gray\", linestyle=\"--\")\n",
    "    ax.legend(['Training', 'Validation'])\n",
    "    \n",
    "    # Latent space samples\n",
    "    ax = axarr[1, 1]\n",
    "    ax.set_title('Samples from latent space')\n",
    "    ax.axis('off')\n",
    "\n",
    "    with torch.no_grad():\n",
    "#         epsilon = torch.from_numpy(grid).float().to(device)\n",
    "        epsilon = torch.randn(batch_size, latent_features).to(device)\n",
    "        samples = torch.sigmoid(net.decoder(epsilon)).detach()\n",
    "\n",
    "    canvas = np.zeros((IMG_SIZE*rows, columns*IMG_SIZE))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            idx = i % columns + rows * j\n",
    "            #temp_img = samples[idx].reshape((224, 224))\n",
    "            #canvas[i*28:(i+1)*28, j*28:(j+1)*28] = resize(temp_img, output_shape=[28,28], mode='reflect', anti_aliasing=True)\n",
    "            canvas[i*IMG_SIZE:(i+1)*IMG_SIZE, j*IMG_SIZE:(j+1)*IMG_SIZE] = samples[idx].reshape((IMG_SIZE, IMG_SIZE))\n",
    "    ax.imshow(canvas, cmap='gray')\n",
    "\n",
    "    # Inputs\n",
    "    ax = axarr[2, 0]\n",
    "    ax.set_title('Inputs')\n",
    "    ax.axis('off')\n",
    "\n",
    "    canvas = np.zeros((IMG_SIZE*rows, columns*IMG_SIZE))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            idx = i % columns + rows * j\n",
    "            #temp_img = x[idx].reshape((224, 224))\n",
    "            #canvas[i*28:(i+1)*28, j*28:(j+1)*28] = resize(temp_img, output_shape=[28,28], mode='reflect', anti_aliasing=True)\n",
    "            canvas[i*IMG_SIZE:(i+1)*IMG_SIZE, j*IMG_SIZE:(j+1)*IMG_SIZE] = x[idx].reshape((IMG_SIZE, IMG_SIZE))\n",
    "    ax.imshow(canvas, cmap='gray')\n",
    "\n",
    "    # Reconstructions\n",
    "    ax = axarr[2, 1]\n",
    "    ax.set_title('Reconstructions')\n",
    "    ax.axis('off')\n",
    "\n",
    "    canvas = np.zeros((IMG_SIZE*rows, columns*IMG_SIZE))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            idx = i % columns + rows * j\n",
    "            #temp_img = x_hat[idx].reshape((224, 224))\n",
    "            #canvas[i*28:(i+1)*28, j*28:(j+1)*28] = resize(temp_img, output_shape=[28,28], mode='reflect', anti_aliasing=True)\n",
    "            canvas[i*IMG_SIZE:(i+1)*IMG_SIZE, j*IMG_SIZE:(j+1)*IMG_SIZE] = x_hat[idx].reshape((IMG_SIZE, IMG_SIZE))\n",
    "    ax.imshow(canvas, cmap='gray')\n",
    "    \n",
    "    plt.savefig(tmp_img)\n",
    "    plt.close(f)\n",
    "    display(Image(filename=tmp_img))\n",
    "    #clear_output(wait=True)\n",
    "\n",
    "    os.remove(tmp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.sum(torch.isnan(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
