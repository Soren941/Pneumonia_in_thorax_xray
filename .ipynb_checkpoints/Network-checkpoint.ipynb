{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas\n",
    "! pip install pydicom\n",
    "! pip install seaborn\n",
    "\n",
    "import glob, pylab, pandas as pd\n",
    "import pydicom, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from skimage.transform import resize\n",
    "from skimage.exposure import equalize_hist\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.dark_palette(\"purple\"))\n",
    "\n",
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import reduce\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, Dropout2d, MaxPool2d, BatchNorm1d, BatchNorm2d, ReLU, ELU,ConvTranspose2d, MaxUnpool2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax, dropout, dropout2d\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n",
      "CNN_VAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(15, 15), stride=(2, 2), padding=(7, 7))\n",
      "    (1): MaxPool2d(kernel_size=4, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout2d(p=0.2)\n",
      "    (5): Conv2d(8, 16, kernel_size=(11, 11), stride=(2, 2), padding=(5, 5))\n",
      "    (6): MaxPool2d(kernel_size=4, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): Dropout2d(p=0.2)\n",
      "    (10): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (11): MaxPool2d(kernel_size=4, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "    (12): ReLU()\n",
      "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Dropout2d(p=0.2)\n",
      "    (15): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (16): MaxPool2d(kernel_size=4, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "    (17): ReLU()\n",
      "    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): Dropout2d(p=0.2)\n",
      "  )\n",
      "  (CNN_to_latent): Linear(in_features=1600, out_features=8, bias=True)\n",
      "  (latent_to_CNN): Linear(in_features=4, out_features=1600, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): MaxUnpool2d(kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout2d(p=0.2)\n",
      "    (5): ConvTranspose2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (6): MaxUnpool2d(kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): Dropout2d(p=0.2)\n",
      "    (10): ConvTranspose2d(16, 8, kernel_size=(11, 11), stride=(2, 2), padding=(5, 5))\n",
      "    (11): MaxUnpool2d(kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (12): ReLU()\n",
      "    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Dropout2d(p=0.2)\n",
      "    (15): ConvTranspose2d(8, 1, kernel_size=(15, 15), stride=(2, 2), padding=(7, 7))\n",
      "    (16): MaxUnpool2d(kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (17): ReLU()\n",
      "    (18): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): Dropout2d(p=0.2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define size variables\n",
    "IMG_SIZE = 224\n",
    "height = IMG_SIZE\n",
    "width = IMG_SIZE\n",
    "channels = 1\n",
    "num_features = 224**2\n",
    "\n",
    "# Regulization\n",
    "L2_reg = 1e-6\n",
    "\n",
    "# 1. Conv Layer\n",
    "conv_out_channels = [8, 16, 32, 64]\n",
    "conv_kernel = [15, 11, 5, 5]\n",
    "conv_padding = [7, 5, 2, 2]\n",
    "conv_stride = [2, 2, 1, 1]\n",
    "\n",
    "# 1. MaxPool Layer\n",
    "pool_kernel = 4\n",
    "pool_padding = 2\n",
    "pool_stride = 2\n",
    "\n",
    "# Calculating the dimensions \n",
    "def compute_conv_dim(height, width, kernel_size, padding_size, stride_size):\n",
    "    height_new = int((height - kernel_size + 2 * padding_size) / stride_size + 1)\n",
    "    width_new =  int((width  - kernel_size + 2 * padding_size) / stride_size + 1)\n",
    "    return [height_new, width_new]\n",
    "\n",
    "def compute_final_dimension(height, width, last_num_channels, num_layers):\n",
    "    # First conv layer\n",
    "    CNN_height = height\n",
    "    CNN_width = width\n",
    "    for i in range(num_layers):\n",
    "        # conv layer\n",
    "        CNN_height, CNN_width = compute_conv_dim(CNN_height, CNN_width, conv_kernel[i], conv_padding[i], conv_stride[i])\n",
    "        # maxpool layer\n",
    "        CNN_height, CNN_width = compute_conv_dim(CNN_height, CNN_width, pool_kernel, pool_padding, pool_stride)\n",
    "    final_dim = CNN_height * CNN_width * last_num_channels\n",
    "    print(CNN_height,CNN_width)\n",
    "    return final_dim\n",
    "    \n",
    "######## Image has to be: (num, channels, height, width)!!!! #########\n",
    "class CNN_VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_features, num_samples):\n",
    "        super(CNN_VAE, self).__init__()\n",
    "        \n",
    "        self.latent_features = latent_features\n",
    "        self.num_samples = num_samples\n",
    "        \n",
    "        # Calculate final size of the CNN\n",
    "        self.final_dim = compute_final_dimension(height,width,conv_out_channels[-1],4)\n",
    "        ## CNN encoder\n",
    "        self.encoder = nn.Sequential(            \n",
    "                Conv2d(     in_channels=channels,\n",
    "                            out_channels=conv_out_channels[0],\n",
    "                            kernel_size=conv_kernel[0],\n",
    "                            stride=conv_stride[0],\n",
    "                            padding=conv_padding[0]),\n",
    "            \n",
    "                MaxPool2d(  kernel_size=pool_kernel, \n",
    "                            stride=pool_stride,\n",
    "                            padding=pool_padding),\n",
    "                ReLU(),\n",
    "                BatchNorm2d(conv_out_channels[0]),\n",
    "                Dropout2d(p=0.2),\n",
    "            \n",
    "                Conv2d(     in_channels=conv_out_channels[0],\n",
    "                            out_channels=conv_out_channels[1],\n",
    "                            kernel_size=conv_kernel[1],\n",
    "                            stride=conv_stride[1],\n",
    "                            padding=conv_padding[1]),\n",
    "            \n",
    "                MaxPool2d(  kernel_size=pool_kernel, \n",
    "                            stride=pool_stride,\n",
    "                            padding=pool_padding),\n",
    "                ReLU(),\n",
    "                BatchNorm2d(conv_out_channels[1]),\n",
    "                Dropout2d(p=0.2),\n",
    "            \n",
    "                Conv2d(     in_channels=conv_out_channels[1],\n",
    "                            out_channels=conv_out_channels[2],\n",
    "                            kernel_size=conv_kernel[2],\n",
    "                            stride=conv_stride[2],\n",
    "                            padding=conv_padding[2]),\n",
    "            \n",
    "                MaxPool2d(  kernel_size=pool_kernel, \n",
    "                            stride=pool_stride,\n",
    "                            padding=pool_padding),\n",
    "                ReLU(),\n",
    "                BatchNorm2d(conv_out_channels[2]),\n",
    "                Dropout2d(p=0.2),\n",
    "                \n",
    "                Conv2d(     in_channels=conv_out_channels[2],\n",
    "                            out_channels=conv_out_channels[3],\n",
    "                            kernel_size=conv_kernel[3],\n",
    "                            stride=conv_stride[3],\n",
    "                            padding=conv_padding[3]),\n",
    "            \n",
    "                MaxPool2d(  kernel_size=pool_kernel, \n",
    "                            stride=pool_stride,\n",
    "                            padding=pool_padding),\n",
    "                ReLU(),\n",
    "                BatchNorm2d(conv_out_channels[3]),\n",
    "                Dropout2d(p=0.2),\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.CNN_to_latent = Linear(in_features=self.final_dim, out_features=self.latent_features*2)\n",
    "        self.latent_to_CNN = Linear(in_features=self.latent_features, out_features=self.final_dim)\n",
    "        # The latent code must be decoded into the original image\n",
    "        self.decoder = nn.Sequential(      \n",
    "            ConvTranspose2d(     in_channels=conv_out_channels[3],\n",
    "                        out_channels=conv_out_channels[2],\n",
    "                        kernel_size=conv_kernel[3],\n",
    "                        stride=conv_stride[3],\n",
    "                        padding=conv_padding[3]),\n",
    "\n",
    "            MaxUnpool2d(  kernel_size=pool_kernel, \n",
    "                        stride=pool_stride,\n",
    "                        padding=pool_padding),\n",
    "            ReLU(),\n",
    "            BatchNorm2d(conv_out_channels[3]),\n",
    "            Dropout2d(p=0.2),\n",
    "            \n",
    "            ConvTranspose2d(     in_channels=conv_out_channels[2],\n",
    "                        out_channels=conv_out_channels[1],\n",
    "                        kernel_size=conv_kernel[2],\n",
    "                        stride=conv_stride[2],\n",
    "                        padding=conv_padding[2]),\n",
    "\n",
    "            MaxUnpool2d(  kernel_size=pool_kernel, \n",
    "                        stride=pool_stride,\n",
    "                        padding=pool_padding),\n",
    "            ReLU(),\n",
    "            BatchNorm2d(conv_out_channels[2]),\n",
    "            Dropout2d(p=0.2), \n",
    "            \n",
    "            ConvTranspose2d(     in_channels=conv_out_channels[1],\n",
    "                        out_channels=conv_out_channels[0],\n",
    "                        kernel_size=conv_kernel[1],\n",
    "                        stride=conv_stride[1],\n",
    "                        padding=conv_padding[1]),\n",
    "\n",
    "            MaxUnpool2d(  kernel_size=pool_kernel, \n",
    "                        stride=pool_stride,\n",
    "                        padding=pool_padding),\n",
    "            ReLU(),\n",
    "            BatchNorm2d(conv_out_channels[1]),\n",
    "            Dropout2d(p=0.2),\n",
    "            \n",
    "            ConvTranspose2d(     in_channels=conv_out_channels[0],\n",
    "                        out_channels=channels,\n",
    "                        kernel_size=conv_kernel[0],\n",
    "                        stride=conv_stride[0],\n",
    "                        padding=conv_padding[0]),\n",
    "\n",
    "            MaxUnpool2d(  kernel_size=pool_kernel, \n",
    "                        stride=pool_stride,\n",
    "                        padding=pool_padding),\n",
    "            ReLU(),\n",
    "            BatchNorm2d(conv_out_channels[0]),\n",
    "            Dropout2d(p=0.2) \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        outputs = {}\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view( batch_size, -1)\n",
    "        x = self.CNN_to_latent(x)\n",
    "        \n",
    "        \n",
    "        # Split encoder outputs into a mean and variance vector\n",
    "        mu, log_var = torch.chunk(x, 2, dim=-1)\n",
    "        \n",
    "        # Make sure that the log variance is positive\n",
    "        log_var = softplus(log_var)\n",
    "        \n",
    "        # :- Reparametrisation trick\n",
    "        # a sample from N(mu, sigma) is mu + sigma * epsilon\n",
    "        # where epsilon ~ N(0, 1)\n",
    "                \n",
    "        # Don't propagate gradients through randomness\n",
    "        with torch.no_grad():\n",
    "            batch_size = mu.size(0)\n",
    "            epsilon = torch.randn(batch_size, self.num_samples, self.latent_features)\n",
    "            \n",
    "            if cuda:\n",
    "                epsilon = epsilon.cuda()\n",
    "        \n",
    "        sigma = torch.exp(log_var/2)\n",
    "        \n",
    "        # We will need to unsqueeze to turn\n",
    "        # (batch_size, latent_dim) -> (batch_size, 1, latent_dim)\n",
    "        z = mu.unsqueeze(1) + epsilon * sigma.unsqueeze(1)  \n",
    "        z2 = z.view(batch_size,-1)\n",
    "        # Run through decoder\n",
    "        x = self.latent_to_CNN(z2)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        # The original digits are on the scale [0, 1]\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        # Mean over samples\n",
    "        x_hat = torch.mean(x, dim=1)\n",
    "        \n",
    "        # Resize x_hat from [batch_size, no_features] to [batch_size, channels, height, width]\n",
    "        x_hat = x_hat.view( batch_size, 1, height, width)\n",
    "        \n",
    "        outputs[\"x_hat\"] = x_hat\n",
    "        outputs[\"z\"] = z\n",
    "        outputs[\"mu\"] = mu\n",
    "        outputs[\"log_var\"] = log_var\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "latent_features = 4\n",
    "# The number of samples used then initialising the VAE, \n",
    "# is number of samples drawn from the distribution\n",
    "num_samples = 10\n",
    "\n",
    "net = CNN_VAE(latent_features, num_samples)\n",
    "print(net)\n",
    "# Transfer model to GPU if available\n",
    "if cuda:\n",
    "    net = net.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [32 x 40], m2: [4 x 1600] at /opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/TH/generic/THTensorMath.cpp:2070",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-5a2a78de1097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-78e50ad8c3c2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# Run through decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_to_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [32 x 40], m2: [4 x 1600] at /opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/TH/generic/THTensorMath.cpp:2070"
     ]
    }
   ],
   "source": [
    "x = torch.randn(32, 1, 224,224)\n",
    "y = net.forward(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
