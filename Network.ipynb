{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "! pip install pydicom\n",
    "! pip install seaborn\n",
    "\n",
    "import glob, pylab, pandas as pd\n",
    "import pydicom, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from skimage.transform import resize\n",
    "from skimage.exposure import equalize_hist\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.dark_palette(\"purple\"))\n",
    "\n",
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import reduce\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, Dropout2d, MaxPool2d, BatchNorm1d, BatchNorm2d, ReLU, ELU\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax, dropout, dropout2d\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 57\n",
      "15 15\n",
      "8 8\n",
      "5 5\n",
      "1600\n",
      "CNN_VAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(15, 15), stride=(2, 2), padding=(7, 7))\n",
      "    (1): MaxPool2d(kernel_size=4, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout2d(p=0.2)\n",
      "    (5): Conv2d(1, 16, kernel_size=(11, 11), stride=(2, 2), padding=(5, 5))\n",
      "    (6): MaxPool2d(kernel_size=4, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): Dropout2d(p=0.2)\n",
      "    (10): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (11): MaxPool2d(kernel_size=4, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "    (12): ReLU()\n",
      "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Dropout2d(p=0.2)\n",
      "    (15): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (16): MaxPool2d(kernel_size=4, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "    (17): ReLU()\n",
      "    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): Dropout2d(p=0.2)\n",
      "  )\n",
      "  (CNN_to_latent): Linear(in_features=1600, out_features=8, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): Linear(in_features=256, out_features=50176, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define size variables\n",
    "IMG_SIZE = 224\n",
    "height = IMG_SIZE\n",
    "width = IMG_SIZE\n",
    "channels = 1\n",
    "num_features = 224**2\n",
    "\n",
    "# Regulization\n",
    "L2_reg = 1e-6\n",
    "\n",
    "# 1. Conv Layer\n",
    "conv_out_channels = [8, 16, 32, 64]\n",
    "conv_kernel = [15, 11, 5, 5]\n",
    "conv_padding = [7, 5, 2, 2]\n",
    "conv_stride = [2, 2, 1, 1]\n",
    "\n",
    "# 1. MaxPool Layer\n",
    "pool_kernel = 4\n",
    "pool_padding = 2\n",
    "pool_stride = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######## Image has to be: (num, channels, height, width)!!!! #########\n",
    "class CNN_VAE(nn.Module):\n",
    "    # Calculating the dimensions \n",
    "    def compute_conv_dim(height, width, kernel_size, padding_size, stride_size):\n",
    "        height_new = int((height - kernel_size + 2 * padding_size) / stride_size + 1)\n",
    "        width_new =  int((width  - kernel_size + 2 * padding_size) / stride_size + 1)\n",
    "        return [height_new, width_new]\n",
    "\n",
    "    def compute_final_dimension(height, width, last_num_channels, num_layers):\n",
    "        # First conv layer\n",
    "        CNN_height = height\n",
    "        CNN_width = width\n",
    "        for i in range(num_layers):\n",
    "            # conv layer\n",
    "            CNN_height, CNN_width = compute_conv_dim(CNN_height, CNN_width, conv_kernel[i], conv_padding[i], conv_stride[i])\n",
    "            # maxpool layer\n",
    "            CNN_height, CNN_width = compute_conv_dim(CNN_height, CNN_width, pool_kernel, pool_padding, pool_stride)\n",
    "        final_dim = CNN_height * CNN_width * last_num_channels\n",
    "    return final_dim\n",
    "\n",
    "    def __init__(self, latent_features, num_samples):\n",
    "        super(CNN_VAE, self).__init__()\n",
    "        \n",
    "        self.latent_features = latent_features\n",
    "        self.num_samples = num_samples\n",
    "        \n",
    "        # Calculate final size of the CNN\n",
    "        self.final_dim = compute_final_dimension(height,width,conv_out_channels[-1],4)\n",
    "        print(self.final_dim)\n",
    "        ## CNN encoder\n",
    "        self.encoder = nn.Sequential(            \n",
    "                Conv2d(     in_channels=channels,\n",
    "                            out_channels=conv_out_channels[0],\n",
    "                            kernel_size=conv_kernel[0],\n",
    "                            stride=conv_stride[0],\n",
    "                            padding=conv_padding[0]),\n",
    "            \n",
    "                MaxPool2d(  kernel_size=pool_kernel, \n",
    "                            stride=pool_stride,\n",
    "                            padding=pool_padding),\n",
    "                ReLU(),\n",
    "                BatchNorm2d(conv_out_channels[0]),\n",
    "                Dropout2d(p=0.2),\n",
    "            \n",
    "                Conv2d(     in_channels=channels,\n",
    "                            out_channels=conv_out_channels[1],\n",
    "                            kernel_size=conv_kernel[1],\n",
    "                            stride=conv_stride[1],\n",
    "                            padding=conv_padding[1]),\n",
    "            \n",
    "                MaxPool2d(  kernel_size=pool_kernel, \n",
    "                            stride=pool_stride,\n",
    "                            padding=pool_padding),\n",
    "                ReLU(),\n",
    "                BatchNorm2d(conv_out_channels[1]),\n",
    "                Dropout2d(p=0.2),\n",
    "            \n",
    "                Conv2d(     in_channels=channels,\n",
    "                            out_channels=conv_out_channels[2],\n",
    "                            kernel_size=conv_kernel[2],\n",
    "                            stride=conv_stride[2],\n",
    "                            padding=conv_padding[2]),\n",
    "            \n",
    "                MaxPool2d(  kernel_size=pool_kernel, \n",
    "                            stride=pool_stride,\n",
    "                            padding=pool_padding),\n",
    "                ReLU(),\n",
    "                BatchNorm2d(conv_out_channels[2]),\n",
    "                Dropout2d(p=0.2),\n",
    "                \n",
    "                Conv2d(     in_channels=channels,\n",
    "                            out_channels=conv_out_channels[3],\n",
    "                            kernel_size=conv_kernel[3],\n",
    "                            stride=conv_stride[3],\n",
    "                            padding=conv_padding[3]),\n",
    "            \n",
    "                MaxPool2d(  kernel_size=pool_kernel, \n",
    "                            stride=pool_stride,\n",
    "                            padding=pool_padding),\n",
    "                ReLU(),\n",
    "                BatchNorm2d(conv_out_channels[3]),\n",
    "                Dropout2d(p=0.2),\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.CNN_to_latent = Linear(in_features=self.final_dim, out_features=self.latent_features*2)\n",
    "        \n",
    "        # The latent code must be decoded into the original image\n",
    "        self.decoder = nn.Sequential(\n",
    "            Linear(in_features=self.latent_features, out_features=128),\n",
    "            #BatchNorm1d(num_features=128, eps=1e-3),\n",
    "            ELU(),\n",
    "            Linear(in_features=128, out_features=256),\n",
    "            #BatchNorm1d(num_features=256),\n",
    "            ELU(),\n",
    "            Linear(in_features=256, out_features=num_features)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        outputs = {}\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view( batch_size, -1)\n",
    "        x = self.CNN_to_latent(x)\n",
    "        \n",
    "        # Split encoder outputs into a mean and variance vector\n",
    "        mu, log_var = torch.chunk(x, 2, dim=-1)\n",
    "        \n",
    "        # Make sure that the log variance is positive\n",
    "        log_var = softplus(log_var)\n",
    "        \n",
    "        # :- Reparametrisation trick\n",
    "        # a sample from N(mu, sigma) is mu + sigma * epsilon\n",
    "        # where epsilon ~ N(0, 1)\n",
    "                \n",
    "        # Don't propagate gradients through randomness\n",
    "        with torch.no_grad():\n",
    "            batch_size = mu.size(0)\n",
    "            epsilon = torch.randn(batch_size, self.num_samples, self.latent_features)\n",
    "            \n",
    "            if cuda:\n",
    "                epsilon = epsilon.cuda()\n",
    "        \n",
    "        sigma = torch.exp(log_var/2)\n",
    "        \n",
    "        # We will need to unsqueeze to turn\n",
    "        # (batch_size, latent_dim) -> (batch_size, 1, latent_dim)\n",
    "        z = mu.unsqueeze(1) + epsilon * sigma.unsqueeze(1)  \n",
    "        \n",
    "        # Run through decoder\n",
    "        x = self.decoder(z)\n",
    "        \n",
    "        # The original digits are on the scale [0, 1]\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        # Mean over samples\n",
    "        x_hat = torch.mean(x, dim=1)\n",
    "        \n",
    "        # Resize x_hat from [batch_size, no_features] to [batch_size, channels, height, width]\n",
    "        x_hat = x_hat.view( batch_size, 1, height, width)\n",
    "        \n",
    "        outputs[\"x_hat\"] = x_hat\n",
    "        outputs[\"z\"] = z\n",
    "        outputs[\"mu\"] = mu\n",
    "        outputs[\"log_var\"] = log_var\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "latent_features = 4\n",
    "# The number of samples used then initialising the VAE, \n",
    "# is number of samples drawn from the distribution\n",
    "num_samples = 10\n",
    "\n",
    "net = CNN_VAE(latent_features, num_samples)\n",
    "\n",
    "# Transfer model to GPU if available\n",
    "if cuda:\n",
    "    net = net.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network import CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
